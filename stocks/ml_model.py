#!/usr/bin/env python3
"""
ì£¼ì‹ ë§¤ë§¤ ML ëª¨ë¸ v1.0

XGBoost ë¶„ë¥˜ ëª¨ë¸:
- ì…ë ¥: ê¸°ìˆ ì  ì§€í‘œ + ê°€ê²©/ê±°ë˜ëŸ‰ íŠ¹ì„±
- ì¶œë ¥: 3ì¼ ë‚´ +2% ì´ìƒ ìƒìŠ¹ í™•ë¥ 

ì‚¬ìš©ë²•:
    python3 stocks/ml_model.py train          # ëª¨ë¸ í•™ìŠµ
    python3 stocks/ml_model.py evaluate       # ì„±ê³¼ í‰ê°€(=train)
    python3 stocks/ml_model.py predict 005930 # íŠ¹ì • ì¢…ëª© ì˜ˆì¸¡
    python3 stocks/ml_model.py predict_all    # ì „ì²´ ì¢…ëª© ì˜ˆì¸¡
"""

import os
import json
import sys
import pickle
from pathlib import Path

import numpy as np


def _load_env():
    p = Path('/home/wlsdud5035/.openclaw/openclaw.json')
    if p.exists():
        d = json.loads(p.read_text())
        for k, v in (d.get('env') or {}).items():
            if isinstance(v, str):
                os.environ.setdefault(k, v)


_load_env()

from supabase import create_client  # noqa: E402

SUPABASE_URL = os.environ.get('SUPABASE_URL', '')
SUPABASE_KEY = os.environ.get('SUPABASE_SECRET_KEY', '')
supabase = create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL and SUPABASE_KEY else None

MODEL_PATH = Path(__file__).parent / 'xgb_model.pkl'
FEATURE_NAMES = [
    'rsi_14',
    'rsi_7',
    'macd',
    'macd_histogram',
    'macd_signal',
    'bb_pos',
    'bb_width_pct',
    'vol_ratio_5',
    'vol_ratio_20',
    'return_1d',
    'return_3d',
    'return_5d',
    'return_10d',
    'return_20d',
    'high_low_range',
    'close_vs_ma5',
    'close_vs_ma20',
    'close_vs_ma60',
    'atr_14',
    'volume_trend',
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”¼ì²˜ ê³„ì‚°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def calc_ema(data, period):
    if len(data) < period:
        return data[-1] if data else 0
    k = 2 / (period + 1)
    e = data[0]
    for d in data[1:]:
        e = d * k + e * (1 - k)
    return e


def calc_rsi(closes, period=14):
    if len(closes) < period + 1:
        return 50
    gains, losses = [], []
    for i in range(-period, 0):
        diff = closes[i] - closes[i - 1]
        gains.append(max(diff, 0))
        losses.append(max(-diff, 0))
    avg_gain = sum(gains) / period
    avg_loss = sum(losses) / period
    if avg_loss == 0:
        return 100
    return round(100 - (100 / (1 + avg_gain / avg_loss)), 2)


def calc_atr(highs, lows, closes, period=14):
    if len(closes) < period + 1:
        return 0
    trs = []
    for i in range(-period, 0):
        tr = max(
            highs[i] - lows[i],
            abs(highs[i] - closes[i - 1]),
            abs(lows[i] - closes[i - 1]),
        )
        trs.append(tr)
    return sum(trs) / period


def extract_features(closes, volumes, highs, lows, idx):
    """íŠ¹ì • ì‹œì (idx)ì—ì„œ í”¼ì²˜ ë²¡í„° ì¶”ì¶œ"""
    if idx < 60:  # ìµœì†Œ 60ì¼ í•„ìš”
        return None

    c = closes[: idx + 1]
    v = volumes[: idx + 1]
    h = highs[: idx + 1]
    l = lows[: idx + 1]

    price = c[-1]
    if price <= 0:
        return None

    # RSI
    rsi_14 = calc_rsi(c, 14)
    rsi_7 = calc_rsi(c, 7)

    # MACD
    ema12 = calc_ema(c, 12)
    ema26 = calc_ema(c, 26)
    macd = ema12 - ema26

    macd_line = []
    for i in range(26, len(c)):
        e12 = calc_ema(c[: i + 1], 12)
        e26 = calc_ema(c[: i + 1], 26)
        macd_line.append(e12 - e26)
    macd_sig = calc_ema(macd_line, 9) if len(macd_line) >= 9 else macd
    macd_hist = macd - macd_sig

    # ë³¼ë¦°ì € ë°´ë“œ
    ma20 = sum(c[-20:]) / 20
    std20 = (sum((x - ma20) ** 2 for x in c[-20:]) / 20) ** 0.5
    bb_upper = ma20 + 2 * std20
    bb_lower = ma20 - 2 * std20
    bb_width = bb_upper - bb_lower
    bb_pos = (price - bb_lower) / bb_width * 100 if bb_width > 0 else 50
    bb_width_pct = bb_width / ma20 * 100 if ma20 > 0 else 0

    # ê±°ë˜ëŸ‰
    avg_vol_5 = sum(v[-6:-1]) / 5 if len(v) >= 6 else 1
    avg_vol_20 = sum(v[-21:-1]) / 20 if len(v) >= 21 else 1
    vol_ratio_5 = v[-1] / avg_vol_5 if avg_vol_5 > 0 else 1
    vol_ratio_20 = v[-1] / avg_vol_20 if avg_vol_20 > 0 else 1

    # ìˆ˜ìµë¥ 
    return_1d = (c[-1] / c[-2] - 1) * 100 if len(c) >= 2 else 0
    return_3d = (c[-1] / c[-4] - 1) * 100 if len(c) >= 4 else 0
    return_5d = (c[-1] / c[-6] - 1) * 100 if len(c) >= 6 else 0
    return_10d = (c[-1] / c[-11] - 1) * 100 if len(c) >= 11 else 0
    return_20d = (c[-1] / c[-21] - 1) * 100 if len(c) >= 21 else 0

    # ì¼ì¼ ê³ ì € ë²”ìœ„
    high_low_range = (h[-1] - l[-1]) / price * 100

    # ì´ë™í‰ê·  ëŒ€ë¹„
    ma5 = sum(c[-5:]) / 5
    ma60 = sum(c[-60:]) / 60 if len(c) >= 60 else ma20
    close_vs_ma5 = (price / ma5 - 1) * 100
    close_vs_ma20 = (price / ma20 - 1) * 100
    close_vs_ma60 = (price / ma60 - 1) * 100

    # ATR
    atr = calc_atr(h, l, c, 14)
    atr_pct = atr / price * 100 if price > 0 else 0

    # ê±°ë˜ëŸ‰ ì¶”ì„¸
    vol_trend = avg_vol_5 / avg_vol_20 if avg_vol_20 > 0 else 1

    # ì¼ë¶€ í”¼ì²˜ëŠ” ê°€ê²©ìœ¼ë¡œ ì •ê·œí™”
    return [
        rsi_14,
        rsi_7,
        macd / price * 100,
        macd_hist / price * 100,
        macd_sig / price * 100,
        bb_pos,
        bb_width_pct,
        vol_ratio_5,
        vol_ratio_20,
        return_1d,
        return_3d,
        return_5d,
        return_10d,
        return_20d,
        high_low_range,
        close_vs_ma5,
        close_vs_ma20,
        close_vs_ma60,
        atr_pct,
        vol_trend,
    ]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ì¤€ë¹„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_training_data(target_days=3, target_return=0.02):
    """
    DBì—ì„œ í•™ìŠµ ë°ì´í„° ìƒì„±

    ë¼ë²¨: target_daysì¼ í›„ ìˆ˜ìµë¥  >= target_returnì´ë©´ 1(ë§¤ìˆ˜), ì•„ë‹ˆë©´ 0(ê´€ë§)
    """
    if not supabase:
        print('Supabase ë¯¸ì—°ê²°')
        return None, None

    stocks = (
        supabase.table('top50_stocks')
        .select('stock_code')
        .execute()
        .data
        or []
    )
    print(f'ë°ì´í„° ë¡œë“œ: {len(stocks)}ì¢…ëª©')

    all_X = []
    all_y = []

    for s in stocks:
        code = s['stock_code']
        rows = (
            supabase.table('daily_ohlcv')
            .select('date,open_price,high_price,low_price,close_price,volume')
            .eq('stock_code', code)
            .order('date', desc=False)
            .execute()
            .data
            or []
        )

        if len(rows) < 80:
            continue

        closes = [float(r['close_price']) for r in rows]
        volumes = [float(r.get('volume', 0)) for r in rows]
        highs = [float(r.get('high_price', r['close_price'])) for r in rows]
        lows = [float(r.get('low_price', r['close_price'])) for r in rows]

        for i in range(60, len(rows) - target_days):
            features = extract_features(closes, volumes, highs, lows, i)
            if features is None:
                continue

            future_return = (closes[i + target_days] - closes[i]) / closes[i]
            label = 1 if future_return >= target_return else 0

            all_X.append(features)
            all_y.append(label)

    if not all_X:
        print('í•™ìŠµ ë°ì´í„° ì—†ìŒ')
        return None, None

    X = np.array(all_X, dtype=float)
    y = np.array(all_y, dtype=int)
    buys = int(y.sum())
    print(f'í•™ìŠµ ë°ì´í„°: {len(X)}ê°œ ìƒ˜í”Œ (ë§¤ìˆ˜: {buys} / ê´€ë§: {len(y) - buys})')
    if len(y) > 0:
        print(f'ë§¤ìˆ˜ ë¹„ìœ¨: {buys / len(y) * 100:.1f}%')

    return X, y


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ëª¨ë¸ í•™ìŠµ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _build_model(scale_pos_weight: float = 1.0):
    """XGBClassifier ì¸ìŠ¤í„´ìŠ¤ ê³µí†µ ìƒì„±."""
    from xgboost import XGBClassifier
    return XGBClassifier(
        n_estimators=200,
        max_depth=5,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        scale_pos_weight=scale_pos_weight,
        eval_metric='logloss',
        random_state=42,
        use_label_encoder=False,
    )


def walk_forward_validate(X: np.ndarray, y: np.ndarray, n_splits: int = 5) -> dict:
    """
    Walk-forward êµì°¨ê²€ì¦ (ì‹œê³„ì—´ ì „ìš©).

    ê° í´ë“œì—ì„œ ê³¼ê±°ë¡œ í•™ìŠµ â†’ ë¯¸ë˜ë¡œ ê²€ì¦.
    ëœë¤ ë¶„í•  ê¸ˆì§€ (ë¯¸ë˜ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€).

    Returns:
        {
          'fold_aucs': list[float],
          'fold_precisions': list[float],
          'mean_auc': float,
          'mean_precision': float,
          'std_auc': float,
        }
    """
    try:
        from xgboost import XGBClassifier
        from sklearn.model_selection import TimeSeriesSplit
        from sklearn.metrics import roc_auc_score, precision_score
    except ImportError as e:
        print(f'ì˜ì¡´ì„± ë¶€ì¡±: {e}')
        return {}

    tscv = TimeSeriesSplit(n_splits=n_splits)
    fold_aucs, fold_precisions = [], []

    print(f'\n=== Walk-forward êµì°¨ê²€ì¦ ({n_splits}í´ë“œ) ===')
    for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):
        X_tr, X_te = X[train_idx], X[test_idx]
        y_tr, y_te = y[train_idx], y[test_idx]

        if len(np.unique(y_te)) < 2:
            continue  # ë¼ë²¨ ë‹¨ì¼ í´ë“œ ìŠ¤í‚µ

        pos = max(int(y_tr.sum()), 1)
        neg = max(len(y_tr) - pos, 1)
        model = _build_model(scale_pos_weight=neg / pos)
        model.fit(X_tr, y_tr, verbose=False)

        y_prob = model.predict_proba(X_te)[:, 1]
        y_pred = (y_prob >= 0.65).astype(int)

        auc = roc_auc_score(y_te, y_prob)
        prec = precision_score(y_te, y_pred, zero_division=0)

        fold_aucs.append(auc)
        fold_precisions.append(prec)
        print(f'  Fold {fold}: AUC={auc:.3f}  Precision@0.65={prec:.3f}  '
              f'(train={len(X_tr)}, test={len(X_te)})')

    if not fold_aucs:
        return {}

    result = {
        'fold_aucs':       fold_aucs,
        'fold_precisions': fold_precisions,
        'mean_auc':        round(float(np.mean(fold_aucs)), 4),
        'std_auc':         round(float(np.std(fold_aucs)), 4),
        'mean_precision':  round(float(np.mean(fold_precisions)), 4),
    }
    print(f'\n  í‰ê·  AUC: {result["mean_auc"]:.3f} Â± {result["std_auc"]:.3f}')
    print(f'  í‰ê·  Precision@0.65: {result["mean_precision"]:.3f}')
    return result


def compute_shap_values(model, X_sample: np.ndarray) -> dict:
    """
    SHAP ê°’ìœ¼ë¡œ í”¼ì²˜ ê¸°ì—¬ë„ ë¶„ì„.

    Args:
        model: í•™ìŠµëœ XGBClassifier
        X_sample: ë¶„ì„í•  ìƒ˜í”Œ (ìµœëŒ€ 500ê°œ ì‚¬ìš©)

    Returns:
        {'feature': shap_mean_abs, ...} â€” ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    """
    try:
        import shap
    except ImportError:
        print('shap ë¯¸ì„¤ì¹˜: pip install shap')
        return {}

    sample = X_sample[:500] if len(X_sample) > 500 else X_sample
    explainer = shap.TreeExplainer(model)
    shap_vals = explainer.shap_values(sample)

    # ì´ì§„ ë¶„ë¥˜: shap_vals shape = (n_samples, n_features)
    if isinstance(shap_vals, list):
        shap_vals = shap_vals[1]  # í´ë˜ìŠ¤ 1 (ë§¤ìˆ˜)

    mean_abs = np.abs(shap_vals).mean(axis=0)
    ranking = sorted(
        zip(FEATURE_NAMES, mean_abs.tolist()),
        key=lambda x: x[1], reverse=True,
    )

    print('\n=== SHAP í”¼ì²˜ ê¸°ì—¬ë„ (í‰ê·  ì ˆëŒ“ê°’) ===')
    for name, val in ranking[:10]:
        bar = 'â–ˆ' * int(val * 200)
        print(f'  {name:<20} {val:.4f}  {bar}')

    return {name: round(val, 6) for name, val in ranking}


def train_model():
    """XGBoost ëª¨ë¸ í•™ìŠµ (Walk-forward + SHAP + AUC í¬í•¨)."""
    try:
        from xgboost import XGBClassifier
    except ImportError:
        print('xgboost ë¯¸ì„¤ì¹˜. pip install xgboost')
        return

    from sklearn.metrics import (
        classification_report, accuracy_score,
        roc_auc_score, average_precision_score,
    )

    X, y = load_training_data(target_days=3, target_return=0.02)
    if X is None or len(X) < 100:
        print('ë°ì´í„° ë¶€ì¡± (ìµœì†Œ 100ê°œ í•„ìš”)')
        return

    # â”€â”€ Walk-forward êµì°¨ê²€ì¦ â”€â”€
    wf = walk_forward_validate(X, y, n_splits=5)

    # â”€â”€ ìµœì¢… ëª¨ë¸: ì• 80% í•™ìŠµ / ë’¤ 20% OOS í…ŒìŠ¤íŠ¸ â”€â”€
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]

    print(f'\nìµœì¢… ëª¨ë¸ í•™ìŠµ: {len(X_train)}ê°œ / OOS í…ŒìŠ¤íŠ¸: {len(X_test)}ê°œ')

    pos = max(int(y_train.sum()), 1)
    neg = max(len(y_train) - pos, 1)
    model = _build_model(scale_pos_weight=neg / pos)
    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)

    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]

    print('\n=== OOS ëª¨ë¸ ì„±ê³¼ ===')
    print(f'  ì •í™•ë„:     {accuracy_score(y_test, y_pred) * 100:.1f}%')
    if len(np.unique(y_test)) > 1:
        print(f'  AUC-ROC:    {roc_auc_score(y_test, y_prob):.3f}')
        print(f'  AP (PR):    {average_precision_score(y_test, y_prob):.3f}')
    print(classification_report(y_test, y_pred, target_names=['ê´€ë§', 'ë§¤ìˆ˜']))

    # â”€â”€ XGBoost í”¼ì²˜ ì¤‘ìš”ë„ â”€â”€
    importances = sorted(
        zip(FEATURE_NAMES, model.feature_importances_),
        key=lambda x: x[1], reverse=True,
    )
    print('\n=== XGBoost í”¼ì²˜ ì¤‘ìš”ë„ TOP 10 ===')
    for name, imp in importances[:10]:
        print(f'  {name}: {imp:.4f}')

    # â”€â”€ SHAP ë¶„ì„ â”€â”€
    shap_ranking = compute_shap_values(model, X_test)

    # â”€â”€ í™•ë¥  ì„ê³„ê°’ë³„ ìŠ¹ë¥  â”€â”€
    thresholds = [0.5, 0.6, 0.65, 0.7, 0.8]
    print('\n=== í™•ë¥  ì„ê³„ê°’ë³„ Precision ===')
    for thresh in thresholds:
        mask = y_prob >= thresh
        if mask.sum() == 0:
            continue
        prec = y_test[mask].sum() / mask.sum() * 100
        print(f'  â‰¥{thresh:.2f}: {int(mask.sum())}ê±´ â†’ Precision {prec:.1f}%')

    # â”€â”€ ëª¨ë¸ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥ â”€â”€
    meta = {
        'walk_forward': wf,
        'shap_ranking': list(shap_ranking.items())[:10] if shap_ranking else [],
        'trained_at': str(Path(__file__).stat().st_mtime),
        'n_samples': len(X),
        'feature_importance': [(n, round(float(v), 6)) for n, v in importances],
    }
    META_PATH = MODEL_PATH.with_suffix('.meta.json')
    META_PATH.write_text(json.dumps(meta, ensure_ascii=False, indent=2))

    with open(MODEL_PATH, 'wb') as f:
        pickle.dump(model, f)
    print(f'\nëª¨ë¸ ì €ì¥: {MODEL_PATH}')
    print(f'ë©”íƒ€ ì €ì¥: {META_PATH}')

    return model


def retrain_from_live_trades(min_samples: int = 30) -> bool:
    """
    ì‹¤ì œ ë§¤ë§¤ ê²°ê³¼(trade_executions)ë¡œ ëª¨ë¸ ì¬í•™ìŠµ (ì˜¨ë¼ì¸ í•™ìŠµ).

    XGBoostì˜ incremental fitì€ ë¶€ì¬ â†’ ì „ì²´ ì¬í•™ìŠµì´ì§€ë§Œ
    ë¼ì´ë¸Œ ê±°ë˜ ë¼ë²¨(ì„±ê³µ/ì‹¤íŒ¨)ì„ ì¶”ê°€ í•™ìŠµ ë°ì´í„°ë¡œ í¬í•¨.

    Args:
        min_samples: ì¬í•™ìŠµ ìµœì†Œ ë¼ì´ë¸Œ ìƒ˜í”Œ ìˆ˜

    Returns:
        True if ì¬í•™ìŠµ ì„±ê³µ
    """
    if not supabase:
        print('Supabase ë¯¸ì—°ê²°')
        return False

    # ì‹¤ë§¤ë§¤ ê²°ê³¼ ë¡œë“œ
    try:
        rows = (
            supabase.table('trade_executions')
            .select('stock_code,price,result,pnl_pct,created_at')
            .in_('result', ['CLOSED', 'SELL'])
            .order('created_at', desc=False)
            .execute()
            .data or []
        )
    except Exception as e:
        print(f'ê±°ë˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}')
        return False

    if len(rows) < min_samples:
        print(f'ë¼ì´ë¸Œ ìƒ˜í”Œ ë¶€ì¡±: {len(rows)} < {min_samples}')
        return False

    # ë¼ì´ë¸Œ ë¼ë²¨ ìƒì„±: pnl_pct >= 2% â†’ 1(ì„±ê³µ)
    live_X, live_y = [], []
    for r in rows:
        code = r.get('stock_code', '')
        pred = predict_stock(code)
        if 'error' in pred:
            continue
        features = list(pred['features'].values())
        pnl = float(r.get('pnl_pct') or 0)
        label = 1 if pnl >= 2.0 else 0
        live_X.append(features)
        live_y.append(label)

    if len(live_X) < min_samples:
        print(f'ìœ íš¨ ë¼ì´ë¸Œ ìƒ˜í”Œ ë¶€ì¡±: {len(live_X)}')
        return False

    # íˆìŠ¤í† ë¦¬ì»¬ ë°ì´í„°ì™€ ë³‘í•©
    X_hist, y_hist = load_training_data()
    if X_hist is not None and len(X_hist) > 0:
        X_all = np.vstack([X_hist, np.array(live_X, dtype=float)])
        y_all = np.concatenate([y_hist, np.array(live_y, dtype=int)])
    else:
        X_all = np.array(live_X, dtype=float)
        y_all = np.array(live_y, dtype=int)

    live_wins = sum(live_y)
    print(f'\nì‹¤ë§¤ë§¤ ë°ì´í„° {len(live_X)}ê±´ ì¶”ê°€ (ì„±ê³µ: {live_wins} / ì‹¤íŒ¨: {len(live_y)-live_wins})')
    print(f'ì „ì²´ í•™ìŠµ ë°ì´í„°: {len(X_all)}ê±´')

    # ì¬í•™ìŠµ
    pos = max(int(y_all.sum()), 1)
    neg = max(len(y_all) - pos, 1)
    model = _build_model(scale_pos_weight=neg / pos)
    split_idx = int(len(X_all) * 0.85)
    model.fit(
        X_all[:split_idx], y_all[:split_idx],
        eval_set=[(X_all[split_idx:], y_all[split_idx:])],
        verbose=False,
    )

    with open(MODEL_PATH, 'wb') as f:
        pickle.dump(model, f)
    print(f'ì‹¤ë§¤ë§¤ ë°˜ì˜ ëª¨ë¸ ì €ì¥: {MODEL_PATH}')
    return True


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì˜ˆì¸¡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_model():
    if not MODEL_PATH.exists():
        return None
    with open(MODEL_PATH, 'rb') as f:
        return pickle.load(f)


def predict_stock(stock_code: str) -> dict:
    """íŠ¹ì • ì¢…ëª© ë§¤ìˆ˜ í™•ë¥  ì˜ˆì¸¡"""
    if not supabase:
        return {'error': 'Supabase ë¯¸ì—°ê²°'}
    model = _load_model()
    if model is None:
        return {'error': 'ëª¨ë¸ ì—†ìŒ. train ë¨¼ì € ì‹¤í–‰'}

    rows = (
        supabase.table('daily_ohlcv')
        .select('date,open_price,high_price,low_price,close_price,volume')
        .eq('stock_code', stock_code)
        .order('date', desc=False)
        .limit(120)
        .execute()
        .data
        or []
    )

    if len(rows) < 61:
        return {'error': f'ë°ì´í„° ë¶€ì¡±: {len(rows)}ì¼'}

    closes = [float(r['close_price']) for r in rows]
    volumes = [float(r.get('volume', 0)) for r in rows]
    highs = [float(r.get('high_price', r['close_price'])) for r in rows]
    lows = [float(r.get('low_price', r['close_price'])) for r in rows]

    features = extract_features(closes, volumes, highs, lows, len(rows) - 1)
    if features is None:
        return {'error': 'í”¼ì²˜ ì¶”ì¶œ ì‹¤íŒ¨'}

    X = np.array([features], dtype=float)
    prob = float(model.predict_proba(X)[0][1])
    action = 'BUY' if prob >= 0.65 else 'HOLD'

    return {
        'stock_code': stock_code,
        'buy_probability': round(prob * 100, 1),
        'action': action,
        'features': {
            name: round(val, 4) for name, val in zip(FEATURE_NAMES, features)
        },
    }


def predict_all() -> list:
    """ì „ ì¢…ëª© ë§¤ìˆ˜ í™•ë¥  ì˜ˆì¸¡ â†’ ìƒìœ„ ì¢…ëª© ë°˜í™˜"""
    if not supabase:
        print('Supabase ë¯¸ì—°ê²°')
        return []
    model = _load_model()
    if model is None:
        print('ëª¨ë¸ ì—†ìŒ')
        return []

    stocks = (
        supabase.table('top50_stocks')
        .select('stock_code,stock_name')
        .execute()
        .data
        or []
    )
    results = []

    for s in stocks:
        pred = predict_stock(s['stock_code'])
        if 'error' in pred:
            continue
        pred['name'] = s.get('stock_name', s['stock_code'])
        results.append(pred)

    results.sort(key=lambda x: x['buy_probability'], reverse=True)

    print('\n=== ë§¤ìˆ˜ í™•ë¥  TOP 10 ===')
    for r in results[:10]:
        emoji = 'ğŸŸ¢' if r['action'] == 'BUY' else 'âšª'
        print(f"  {emoji} {r['name']}: {r['buy_probability']}% â†’ {r['action']}")

    print(f'\në§¤ìˆ˜ ì‹ í˜¸: {sum(1 for r in results if r["action"] == "BUY")}ì¢…ëª©')
    return results


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# trading_agent ì—°ë™ìš© í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_ml_signal(stock_code: str) -> dict:
    """
    trading_agentì—ì„œ í˜¸ì¶œí•˜ëŠ” ì¸í„°í˜ì´ìŠ¤

    Returns:
        {
            'action': 'BUY' | 'HOLD',
            'confidence': 0~100,
            'source': 'ML_XGBOOST',
        }
    """
    try:
        pred = predict_stock(stock_code)
        if 'error' in pred:
            return {'action': 'HOLD', 'confidence': 0, 'source': 'ML_ERROR'}

        return {
            'action': pred['action'],
            'confidence': pred['buy_probability'],
            'source': 'ML_XGBOOST',
        }
    except Exception as e:
        return {'action': 'HOLD', 'confidence': 0, 'source': f'ML_ERROR: {e}'}


if __name__ == '__main__':
    cmd = sys.argv[1] if len(sys.argv) > 1 else 'train'

    if cmd == 'train':
        train_model()
    elif cmd == 'predict' and len(sys.argv) > 2:
        result = predict_stock(sys.argv[2])
        print(json.dumps(result, indent=2, ensure_ascii=False))
    elif cmd == 'predict_all':
        predict_all()
    elif cmd == 'evaluate':
        train_model()
    elif cmd == 'retrain':
        # ì‹¤ë§¤ë§¤ ê²°ê³¼ë¡œ ì¬í•™ìŠµ
        min_s = int(sys.argv[2]) if len(sys.argv) > 2 else 30
        ok = retrain_from_live_trades(min_samples=min_s)
        print('ì¬í•™ìŠµ ì„±ê³µ' if ok else 'ì¬í•™ìŠµ ì‹¤íŒ¨')
    elif cmd == 'validate':
        # Walk-forward ê²€ì¦ë§Œ ì‹¤í–‰
        X, y = load_training_data()
        if X is not None:
            walk_forward_validate(X, y)
    elif cmd == 'shap' and len(sys.argv) > 2:
        # íŠ¹ì • ì¢…ëª© SHAP ë¶„ì„
        res = predict_stock(sys.argv[2])
        if 'error' not in res:
            model = _load_model()
            if model:
                feats = np.array([list(res['features'].values())], dtype=float)
                compute_shap_values(model, feats)
    else:
        print('ì‚¬ìš©ë²•:')
        print('  python3 ml_model.py train              # ì „ì²´ í•™ìŠµ + Walk-forward + SHAP')
        print('  python3 ml_model.py validate           # Walk-forward ê²€ì¦ë§Œ')
        print('  python3 ml_model.py retrain [n]        # ì‹¤ë§¤ë§¤ ê²°ê³¼ ë°˜ì˜ ì¬í•™ìŠµ')
        print('  python3 ml_model.py predict 005930     # íŠ¹ì • ì¢…ëª© ì˜ˆì¸¡')
        print('  python3 ml_model.py shap 005930        # íŠ¹ì • ì¢…ëª© SHAP ë¶„ì„')
        print('  python3 ml_model.py predict_all        # ì „ì²´ ì¢…ëª© ì˜ˆì¸¡')

